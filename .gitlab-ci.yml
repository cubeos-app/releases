# =============================================================================
# CubeOS Coreapps Pipeline - Validate, Build, Deploy, Image
# =============================================================================
# 
# Features:
# - Automatic OpenAPI spec generation from swaggo annotations
# - Multi-arch builds (ARM64 + AMD64)
# - Swagger UI auto-updates on each deploy
# - Buildable coreapps (cubeos-docsindex) built on Pi during deploy
# - Deleted apps automatically cleaned up from Pi
# - Packer image build with coreapps bundle (manual trigger)
#
stages:
  - validate
  - build
  - package
  - deploy
  - restart
  - image

variables:
  CUBEOS_VERSION: "0.1.0-alpha.6"
  CUBEOS_SUBNET: "10.42.24.0/24"
  CUBEOS_GATEWAY: "10.42.24.1"
  CUBEOS_DOMAIN: "cubeos.cube"
  # Service classification
  COMPOSE_SERVICES: "pihole npm cubeos-hal"
  STACK_SERVICES: "registry cubeos-api cubeos-dashboard cubeos-docsindex cubeos-filebrowser dozzle ollama chromadb"
  # Buildable stacks: these have src/ directories and need local image build before deploy
  BUILDABLE_STACKS: "cubeos-docsindex"
  # HAL image
  HAL_IMAGE: "ghcr.io/cubeos-app/hal"
  BUILDER_IMAGE: "ghcr.io/cubeos-app/api-builder:latest"

validate-compose:
  stage: validate
  image: registry-gitlab.nuclearlighters.net/products/cubeos/coreapps/ci-utils:latest
  tags:
    - multiarch
  script:
    - |
      # Create dummy env files for validation (real files are on Pi)
      mkdir -p /cubeos/config
      touch /cubeos/config/defaults.env
      touch /cubeos/config/secrets.env
      
      for dir in */; do
        if [ -f "${dir}appconfig/docker-compose.yml" ]; then
          echo "Checking ${dir}..."
          docker compose -f "${dir}appconfig/docker-compose.yml" config -q || exit 1
        fi
      done
      echo "âœ… All compose files valid"
  rules:
    - if: $CI_COMMIT_BRANCH

shellcheck:
  stage: validate
  image: registry-gitlab.nuclearlighters.net/products/cubeos/coreapps/ci-utils:latest
  tags:
    - multiarch
  script:
    - find . -name "*.sh" -type f -exec shellcheck -x {} \;
  rules:
    - if: $CI_COMMIT_BRANCH
  allow_failure: true

# -----------------------------------------------------------------------------
# BUILD HAL - Generate OpenAPI docs + Compile Go binary for both architectures
# -----------------------------------------------------------------------------
build-hal:
  stage: build
  tags: [multiarch]
  image: ${BUILDER_IMAGE}
  script:
    - cp -r cubeos-hal/src/. /app/
    - cd /app
    - go mod download
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Generate OpenAPI docs from swaggo annotations
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - echo "ğŸ“š Installing swag CLI..."
    - go install github.com/swaggo/swag/cmd/swag@latest
    - export PATH=$PATH:$(go env GOPATH)/bin
    
    - echo "ğŸ“š Generating OpenAPI spec from annotations..."
    - |
      swag init \
        -g cmd/cubeos-hal/main.go \
        --output ./docs \
        --parseDependency \
        --parseInternal \
        --parseDepth 2 \
        || echo "âš ï¸ Swag init had warnings (may be OK)"
    
    # Copy generated spec to handlers directory (embedded in binary)
    - |
      if [ -f docs/swagger.yaml ]; then
        cp docs/swagger.yaml internal/handlers/openapi.yaml
        echo "âœ… OpenAPI spec generated ($(wc -l < docs/swagger.yaml) lines)"
      elif [ -f docs/swagger.json ]; then
        echo "Converting swagger.json to yaml..."
        python3 -c "import json,yaml; yaml.dump(json.load(open('docs/swagger.json')), open('internal/handlers/openapi.yaml','w'), default_flow_style=False)" 2>/dev/null \
          || cp docs/swagger.json internal/handlers/openapi.yaml
        echo "âœ… OpenAPI spec generated from JSON"
      else
        echo "âš ï¸ No swagger spec generated, using existing openapi.yaml"
      fi
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Build binaries for both architectures
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - echo "ğŸ”¨ Building ARM64 binary..."
    - GOOS=linux GOARCH=arm64 CGO_ENABLED=0 go build -ldflags="-s -w" -o cubeos-hal-arm64 ./cmd/cubeos-hal/
    
    - echo "ğŸ”¨ Building AMD64 binary..."
    - GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -ldflags="-s -w" -o cubeos-hal-amd64 ./cmd/cubeos-hal/
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Copy artifacts to project dir
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    - cp cubeos-hal-arm64 cubeos-hal-amd64 ${CI_PROJECT_DIR}/
    - cp internal/handlers/openapi.yaml ${CI_PROJECT_DIR}/openapi.yaml
    
    # IMPORTANT: Also update the source tree so package-hal gets the new spec
    - cp internal/handlers/openapi.yaml ${CI_PROJECT_DIR}/cubeos-hal/src/internal/handlers/openapi.yaml
    
    - ls -lh ${CI_PROJECT_DIR}/cubeos-hal-* ${CI_PROJECT_DIR}/openapi.yaml
    - echo "âœ… Build complete"
  artifacts:
    paths:
      - cubeos-hal-arm64
      - cubeos-hal-amd64
      - openapi.yaml
      - cubeos-hal/src/internal/handlers/openapi.yaml
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      changes:
        - cubeos-hal/**/*

# -----------------------------------------------------------------------------
# PACKAGE HAL - Build multi-arch Docker image and push to ghcr.io
# -----------------------------------------------------------------------------
package-hal:
  stage: package
  tags: [multiarch]
  image: docker:24
  needs:
    - job: build-hal
      artifacts: true
  before_script:
    - echo "$GHCR_TOKEN" | docker login ghcr.io -u "$GHCR_USER" --password-stdin
    - docker buildx create --name halbuilder --driver docker-container --use
    - docker buildx inspect --bootstrap
  script:
    - |
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Verify generated OpenAPI spec is present
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if [ -f "openapi.yaml" ]; then
        echo "ğŸ“„ Found generated OpenAPI spec ($(wc -l < openapi.yaml) lines)"
        # Copy to Docker build context
        cp openapi.yaml cubeos-hal/src/internal/handlers/openapi.yaml
        echo "âœ… Copied OpenAPI spec to Docker build context"
      else
        echo "âš ï¸ No generated openapi.yaml found, using existing"
      fi
      
      # Show what we're building with
      echo "ğŸ“„ OpenAPI spec in build context:"
      head -20 cubeos-hal/src/internal/handlers/openapi.yaml
      echo "..."
      wc -l cubeos-hal/src/internal/handlers/openapi.yaml
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Build and push multi-arch image
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      cd cubeos-hal/src
      docker buildx build --no-cache \
        --platform linux/amd64,linux/arm64 \
        --push \
        -t ${HAL_IMAGE}:${CI_COMMIT_SHORT_SHA} \
        -t ${HAL_IMAGE}:latest \
        .
    - echo "âœ… Pushed multi-arch ${HAL_IMAGE}:${CI_COMMIT_SHORT_SHA}"
  after_script:
    - docker buildx rm halbuilder || true
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      changes:
        - cubeos-hal/**/*

deploy:
  stage: deploy
  tags:
    - deploy
    - arm64
  script:
    - |
      # Detect changed apps
      CHANGED_APPS=""
      if [ "$CI_COMMIT_BEFORE_SHA" != "0000000000000000000000000000000000000000" ]; then
        CHANGED_APPS=$(git diff --name-only "$CI_COMMIT_BEFORE_SHA" "$CI_COMMIT_SHA" 2>/dev/null \
          | grep -E '^[^/]+/(appconfig|src)/' \
          | cut -d'/' -f1 \
          | sort -u \
          | tr '\n' ' ' \
          | sed 's/ $//' || true)
      fi
      
      # Fallback: if no changes detected but this is a new commit, check all dirs
      if [ -z "$CHANGED_APPS" ]; then
        echo "âš ï¸  No changes detected via git diff, checking for new apps..."
        for dir in */; do
          app="${dir%/}"
          if [ -d "${dir}appconfig" ] && [ ! -d "/cubeos/coreapps/${app}" ]; then
            CHANGED_APPS="$CHANGED_APPS $app"
          fi
        done
        CHANGED_APPS=$(echo "$CHANGED_APPS" | xargs)
      fi
      
      echo "ğŸ“¦ Changed apps: ${CHANGED_APPS:-none}"
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Clean up apps deleted from git but still on Pi
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      DELETED_APPS=""
      for pidir in /cubeos/coreapps/*/; do
        [ ! -d "$pidir" ] && continue
        app=$(basename "$pidir")
        # Skip non-app directories
        case "$app" in scripts|watchdog) continue;; esac
        # If dir exists on Pi but not in git, it was deleted
        if [ ! -d "${app}" ] && [ -d "${pidir}appconfig" ]; then
          DELETED_APPS="$DELETED_APPS $app"
          echo "ğŸ—‘ï¸  Removing deleted app: $app"
          # Stop compose container if running
          (cd "${pidir}appconfig" 2>/dev/null && docker compose down --remove-orphans 2>/dev/null) || true
          # Remove swarm stack if exists
          docker stack rm "$app" 2>/dev/null || true
          # Wait for stack removal
          sleep 3
          # Remove directory
          rm -rf "$pidir"
          echo "  âœ… Cleaned up $app"
        fi
      done
      [ -n "$DELETED_APPS" ] && echo "ğŸ—‘ï¸  Deleted apps:$DELETED_APPS" || echo "ğŸ—‘ï¸  No deleted apps"
      
      # Filter deleted apps out of CHANGED_APPS (they no longer exist)
      if [ -n "$DELETED_APPS" ]; then
        FILTERED=""
        for app in $CHANGED_APPS; do
          STILL_EXISTS=true
          for del in $DELETED_APPS; do
            [ "$app" = "$del" ] && STILL_EXISTS=false && break
          done
          [ "$STILL_EXISTS" = "true" ] && FILTERED="$FILTERED $app"
        done
        CHANGED_APPS=$(echo "$FILTERED" | xargs)
        echo "ğŸ“¦ Changed apps (after cleanup): ${CHANGED_APPS:-none}"
      fi
      
      # Sync ALL configs and source (idempotent)
      for dir in */; do
        if [ -d "${dir}appconfig" ]; then
          mkdir -p "/cubeos/coreapps/${dir}appconfig"
          mkdir -p "/cubeos/coreapps/${dir}appdata"
          rsync -a --delete "${dir}appconfig/" "/cubeos/coreapps/${dir}appconfig/"
          
          # Also sync src/ if it exists (for buildable apps)
          if [ -d "${dir}src" ]; then
            mkdir -p "/cubeos/coreapps/${dir}src"
            rsync -a --delete "${dir}src/" "/cubeos/coreapps/${dir}src/"
          fi
          
          # Sync appdata if it exists (for DNS configs, etc)
          if [ -d "${dir}appdata" ]; then
            rsync -a "${dir}appdata/" "/cubeos/coreapps/${dir}appdata/"
          fi
        fi
      done
      
      # Sync defaults.env
      [ -f defaults.env ] && cp defaults.env /cubeos/coreapps/
      
      # Ensure config directory structure
      mkdir -p /cubeos/config/vpn/{wireguard,openvpn}
      mkdir -p /cubeos/data/registry
      
      # Copy defaults.env to config if not exists
      if [ ! -f /cubeos/config/defaults.env ]; then
        cp defaults.env /cubeos/config/defaults.env
      fi
      
      # Create empty secrets.env if not exists
      if [ ! -f /cubeos/config/secrets.env ]; then
        touch /cubeos/config/secrets.env
        chmod 600 /cubeos/config/secrets.env
      fi
      
      # Sync scripts directory
      if [ -d "scripts" ]; then
        mkdir -p /cubeos/coreapps/scripts
        rsync -a --delete scripts/ /cubeos/coreapps/scripts/
        chmod +x /cubeos/coreapps/scripts/*.sh 2>/dev/null || true
        
        # Install watchdog systemd files if install script exists
        if [ -f "/cubeos/coreapps/scripts/install-watchdog.sh" ]; then
          echo "ğŸ“¦ Installing watchdog systemd files..."
          /cubeos/coreapps/scripts/install-watchdog.sh
        fi
      fi
      
      # Sync root-level scripts
      for f in *.sh; do
        [ -f "$f" ] && cp "$f" /cubeos/coreapps/ && chmod +x /cubeos/coreapps/"$f"
      done
      
      # Write changed apps (space-separated)
      echo "$CHANGED_APPS" > changed_apps.txt
      echo "âœ… Synced to /cubeos/coreapps/"
  artifacts:
    paths:
      - changed_apps.txt
    expire_in: 10 minutes
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  environment:
    name: production

restart-changed:
  stage: restart
  tags:
    - deploy
    - arm64
  needs:
    - deploy
    - job: package-hal
      optional: true
  before_script:
    - echo "$GHCR_TOKEN" | docker login ghcr.io -u "$GHCR_USER" --password-stdin
  script:
    - |
      set -e
      
      CHANGED_APPS=$(cat changed_apps.txt 2>/dev/null | xargs || true)
      
      if [ -z "$CHANGED_APPS" ]; then
        echo "âœ… No app changes detected, skipping restart"
        exit 0
      fi
      
      echo "ğŸ”„ Apps to restart: $CHANGED_APPS"
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # DNS Health Check - ensure we can resolve Docker Hub
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      echo "ğŸŒ Checking DNS resolution..."
      DNS_OK=false
      for attempt in 1 2 3; do
        if getent hosts registry-1.docker.io >/dev/null 2>&1; then
          DNS_OK=true
          break
        fi
        echo "  DNS attempt $attempt failed, waiting..."
        sleep 5
      done
      
      if [ "$DNS_OK" = "false" ]; then
        echo "âŒ DNS resolution failed - is Pi-hole running?"
        echo "   Run: cd /cubeos/coreapps/pihole/appconfig && docker compose up -d"
        exit 1
      fi
      echo "  âœ… DNS OK"
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Ensure Swarm is initialized
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if ! docker info 2>/dev/null | grep -q "Swarm: active"; then
        echo "ğŸ Initializing Docker Swarm..."
        docker swarm init --advertise-addr 10.42.24.1 --task-history-limit 1 2>/dev/null || true
      fi
      
      # Ensure overlay network exists with SWARM scope (not local)
      NETWORK_SCOPE=$(docker network inspect cubeos-network --format '{{.Scope}}' 2>/dev/null || echo "none")
      if [ "$NETWORK_SCOPE" = "local" ]; then
        echo "ğŸŒ Removing local cubeos-network (wrong scope)..."
        docker network rm cubeos-network 2>/dev/null || true
        NETWORK_SCOPE="none"
      fi
      if [ "$NETWORK_SCOPE" = "none" ]; then
        echo "ğŸŒ Creating cubeos-network overlay (swarm scope)..."
        docker network create --driver overlay --attachable --subnet 10.42.25.0/24 cubeos-network
      fi
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Classify apps by deployment type
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      COMPOSE_APPS=""
      STACK_APPS=""
      HAS_PIHOLE=false
      
      for app in $CHANGED_APPS; do
        case "$app" in
          pihole)
            HAS_PIHOLE=true
            ;;
          npm|cubeos-hal)
            COMPOSE_APPS="$COMPOSE_APPS $app"
            ;;
          registry|cubeos-api|cubeos-dashboard|cubeos-docsindex|cubeos-filebrowser|dozzle|ollama|chromadb)
            STACK_APPS="$STACK_APPS $app"
            ;;
          *)
            # Unknown apps - try compose first
            COMPOSE_APPS="$COMPOSE_APPS $app"
            ;;
        esac
      done
      COMPOSE_APPS=$(echo "$COMPOSE_APPS" | xargs)
      STACK_APPS=$(echo "$STACK_APPS" | xargs)
      
      echo "ğŸ“¦ Compose apps: ${COMPOSE_APPS:-none}"
      echo "ğŸ Swarm stacks: ${STACK_APPS:-none}"
      echo "ğŸ”Œ Pi-hole: $HAS_PIHOLE"
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Deploy COMPOSE apps (npm, cubeos-hal, and unknown apps)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      for app in $COMPOSE_APPS; do
        COMPOSE_FILE="/cubeos/coreapps/${app}/appconfig/docker-compose.yml"
        if [ ! -f "$COMPOSE_FILE" ]; then
          echo "âš ï¸  Skipping $app (no docker-compose.yml)"
          continue
        fi
        
        echo "â”€â”€ $app (compose) â”€â”€"
        cd "/cubeos/coreapps/${app}/appconfig"
        
        echo "  ğŸ›‘ Stopping existing..."
        docker rm -f "cubeos-${app}" 2>/dev/null || true
        docker compose down 2>/dev/null || true
        
        # Pull latest image (HAL image was just pushed by package-hal)
        echo "  ğŸ“¥ Pulling..."
        timeout 120 docker compose pull 2>&1 || echo "  âš ï¸  Pull failed, using cached..."
        
        echo "  ğŸš€ Starting..."
        docker compose up -d --pull always
        
        # Health check
        sleep 3
        CONTAINER=$(docker compose ps -q 2>/dev/null | head -1)
        if [ -n "$CONTAINER" ]; then
          for i in $(seq 1 10); do
            STATUS=$(docker inspect --format='{{.State.Status}}' "$CONTAINER" 2>/dev/null || echo "unknown")
            if [ "$STATUS" = "running" ]; then
              echo "  âœ… $app running"
              break
            fi
            [ "$i" -eq 10 ] && echo "  âš ï¸  $app status: $STATUS"
            sleep 3
          done
        else
          echo "  âœ… $app started"
        fi
      done
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Deploy SWARM stacks (with local build for buildable apps)
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      for app in $STACK_APPS; do
        COMPOSE_FILE="/cubeos/coreapps/${app}/appconfig/docker-compose.yml"
        if [ ! -f "$COMPOSE_FILE" ]; then
          echo "âš ï¸  Skipping $app (no docker-compose.yml)"
          continue
        fi
        
        echo "â”€â”€ $app (swarm) â”€â”€"
        
        # â”€â”€ Build local image if this is a buildable app â”€â”€
        SRC_DIR="/cubeos/coreapps/${app}/src"
        if [ -d "$SRC_DIR" ] && [ -f "$SRC_DIR/Dockerfile" ]; then
          echo "  ğŸ”¨ Building local image..."
          LOCAL_IMAGE="${app}:${CI_COMMIT_SHORT_SHA}"
          LOCAL_IMAGE_LATEST="${app}:latest"
          
          docker build -t "$LOCAL_IMAGE" -t "$LOCAL_IMAGE_LATEST" "$SRC_DIR"
          
          # Also tag as the GHCR name so compose image: reference resolves locally
          GHCR_IMAGE=$(grep -oP 'image:\s*\K\S+' "$COMPOSE_FILE" | head -1)
          if [ -n "$GHCR_IMAGE" ]; then
            docker tag "$LOCAL_IMAGE" "$GHCR_IMAGE"
            echo "  âœ… Built and tagged: $LOCAL_IMAGE -> $GHCR_IMAGE"
          else
            echo "  âœ… Built: $LOCAL_IMAGE"
          fi
        fi
        
        # Remove existing stack and stale networks
        echo "  ğŸ›‘ Removing existing stack..."
        docker stack rm "$app" 2>/dev/null || true
        docker network rm "${app}_default" 2>/dev/null || true
        
        # Wait for cleanup
        sleep 3
        
        # Deploy stack with ARM64 workaround
        echo "  ğŸš€ Deploying stack..."
        docker stack deploy \
          -c "$COMPOSE_FILE" \
          --resolve-image=never \
          "$app"
        
        # Wait and check replicas
        sleep 5
        REPLICAS=$(docker stack services "$app" --format "{{.Replicas}}" 2>/dev/null | head -1 || echo "0/0")
        echo "  ğŸ“Š Replicas: $REPLICAS"
        
        # Wait for service to be ready
        for i in $(seq 1 12); do
          REPLICAS=$(docker stack services "$app" --format "{{.Replicas}}" 2>/dev/null | head -1 || echo "0/0")
          if echo "$REPLICAS" | grep -qE "^1/1$|^[0-9]+/[0-9]+$" && [ "$REPLICAS" != "0/1" ]; then
            RUNNING=$(echo "$REPLICAS" | cut -d'/' -f1)
            DESIRED=$(echo "$REPLICAS" | cut -d'/' -f2)
            if [ "$RUNNING" = "$DESIRED" ] && [ "$RUNNING" != "0" ]; then
              echo "  âœ… $app running ($REPLICAS)"
              break
            fi
          fi
          [ "$i" -eq 12 ] && echo "  âš ï¸  $app may still be starting ($REPLICAS)"
          sleep 5
        done
      done
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Restart pihole LAST (if changed) - DNS will briefly drop
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      if [ "$HAS_PIHOLE" = "true" ]; then
        echo ""
        echo "â”€â”€ pihole (compose - DNS will briefly drop) â”€â”€"
        cd "/cubeos/coreapps/pihole/appconfig"
        
        echo "  ğŸ›‘ Stopping existing..."
        docker rm -f cubeos-pihole 2>/dev/null || true
        docker compose down --remove-orphans 2>/dev/null || true
        
        echo "  ğŸ“¥ Pulling..."
        docker compose pull 2>&1 || true
        
        echo "  ğŸš€ Starting..."
        docker compose up -d --pull always
        
        echo "  Waiting for Pi-hole DNS..."
        for i in $(seq 1 30); do
          if getent hosts google.com >/dev/null 2>&1; then
            echo "  âœ… Pi-hole DNS responding"
            break
          fi
          [ "$i" -eq 30 ] && echo "  âš ï¸  Pi-hole may still be starting..."
          sleep 2
        done
      fi
      
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Final status
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      echo ""
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo "ğŸ“Š Final Status"
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo ""
      echo "COMPOSE CONTAINERS:"
      docker ps --format "table {{.Names}}\t{{.Status}}" 2>/dev/null | grep -E "cubeos-|NAME" || echo "  None"
      echo ""
      echo "SWARM STACKS:"
      docker stack ls 2>/dev/null || echo "  None"
      echo ""
      echo "ğŸ“š Swagger UI: http://cubeos.cube:6005/hal/docs"
      echo "ğŸ“„ OpenAPI Spec: http://cubeos.cube:6005/hal/docs/openapi.yaml"
      echo "âœ… Restart complete"
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  environment:
    name: production

# =============================================================================
# BUILD IMAGE - Packer ARM64 image with coreapps bundle (manual trigger)
# =============================================================================
# Clones the coreapps repo at build time to create a coreapps-bundle/
# that packer injects into the image. This replaces stale heredocs and
# ensures compose files in the image always match the coreapps repo.
#
# Trigger: Manual only (Play button in GitLab UI) or via tag push
# Runner: GPU VM (nllei01gpu01) with packer-builder-arm
# =============================================================================
build-image:
  stage: image
  tags:
    - gpu
    - privileged
  variables:
    PACKER_LOG: "1"
  before_script:
    - |
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo "  CubeOS Image Builder â€” v${CUBEOS_VERSION}"
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      # â”€â”€ Clone coreapps repo and prepare bundle â”€â”€
      echo "ğŸ“¦ Cloning coreapps repo..."
      git clone --depth 1 \
        "https://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}/cubeos/coreapps.git" \
        /tmp/coreapps-src

      # Services to bake into the image
      SERVICES="pihole npm cubeos-api cubeos-hal cubeos-dashboard dozzle ollama chromadb registry"

      echo "ğŸ“¦ Preparing coreapps bundle..."
      mkdir -p coreapps-bundle

      for svc in $SERVICES; do
        if [ -d "/tmp/coreapps-src/${svc}" ]; then
          mkdir -p "coreapps-bundle/${svc}"
          # Copy appconfig (compose files, .env)
          if [ -d "/tmp/coreapps-src/${svc}/appconfig" ]; then
            cp -r "/tmp/coreapps-src/${svc}/appconfig" "coreapps-bundle/${svc}/"
          fi
        else
          echo "  âš ï¸  Service ${svc} not found in coreapps repo"
        fi
      done

      # Copy scripts directory (watchdog, deploy, init-swarm, etc.)
      if [ -d "/tmp/coreapps-src/scripts" ]; then
        cp -r /tmp/coreapps-src/scripts coreapps-bundle/
        chmod +x coreapps-bundle/scripts/*.sh 2>/dev/null || true
      fi

      echo "ğŸ“¦ Coreapps bundle contents:"
      find coreapps-bundle -type f | sort
      rm -rf /tmp/coreapps-src

      # â”€â”€ Ensure docker-images directory exists (may be empty) â”€â”€
      mkdir -p docker-images
  script:
    - |
      docker run --rm --privileged \
        -v /dev:/dev \
        -v "${PWD}:/build" \
        mkaczanowski/packer-builder-arm:latest \
        build \
        -var "version=${CUBEOS_VERSION}" \
        -var "base_image_url=file:///build/cubeos-base.img.xz" \
        /build/packer/cubeos.pkr.hcl

      echo ""
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo "  âœ… Image built: cubeos-${CUBEOS_VERSION}-arm64.img"
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ls -lh cubeos-*.img
  artifacts:
    paths:
      - "cubeos-*.img"
    expire_in: 30 days
  rules:
    - if: $CI_COMMIT_TAG =~ /^v/
    - if: $CI_COMMIT_BRANCH == "main"
      when: manual
      allow_failure: true
